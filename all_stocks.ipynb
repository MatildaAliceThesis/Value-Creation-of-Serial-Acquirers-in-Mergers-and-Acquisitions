{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94dddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 10)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 300)\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "from scipy import stats as st\n",
    "import scipy.stats\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c8035",
   "metadata": {},
   "source": [
    "### Data Loading & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2138d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_frame_size = 21 # Counts from the right in excel sheet 21 columns and sets the split between estimation and event window \n",
    "event_sizes = [3,7,11,21] # event window size. This number does not effect estimation window size only event window size\n",
    "OMXPI_csv = \"OMXPI.xlsx_Sheet1\"\n",
    "stock_csv = \"Joggers_SA_Data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9a206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for event_size in event_sizes:\n",
    "    \n",
    "    ### LOADING DATA ---------------------------------------------------  \n",
    "    # Load OMXPI data\n",
    "    omxp_index = pd.read_csv(\"data/\"+OMXPI_csv+\".csv\")\n",
    "    \n",
    "    # load stock data\n",
    "    stock_csv = \"Joggers_SA_Data\"\n",
    "    df_dnb = pd.read_csv (\"data/\"+stock_csv+\".csv\", delimiter=\",\", header=None)\n",
    "\n",
    "    \n",
    "    ### STOCK Calculation ---------------------------------------------- \n",
    "    \n",
    "    # Locate window split in table data \n",
    "    thres = df_dnb.shape[1]-event_frame_size\n",
    "\n",
    "    # Get event window index values \n",
    "    lower_idx, upper_idx = ut.event_win_indexes(thres, event_frame_size, event_size)\n",
    "\n",
    "    # Define variables\n",
    "    stocks_data = pd.DataFrame()\n",
    "    stocks_metadata = pd.DataFrame()\n",
    "    \n",
    "    # Each data entry takes up 3 rows so loop iterations are divide by 3\n",
    "    for it in tqdm(range(int(df_dnb.shape[0]/3))):\n",
    "        # Select stock(relevant rows) based on iterator(it) from table \n",
    "        df_stock = df_dnb.iloc[0+it*3:2+it*3]\n",
    "        # convert to list\n",
    "        stock = df_stock.values.tolist()\n",
    "\n",
    "        # Check for nan values. If true then skip stock\n",
    "        if ut.has_nan_values(stock[1], it): continue\n",
    "\n",
    "        # Convert stock values from strings to floats\n",
    "        stock[1][1:] = [float(i) for i in stock[1][1:]]\n",
    "\n",
    "        # Get the respective OMXPI values\n",
    "        OMXPI_values = ut.get_omxpi_values(omxp_index, stock[0])\n",
    "        stock.append(OMXPI_values)\n",
    "\n",
    "        # Get the stock return values\n",
    "        stock_return_values = ut.stock_return_values(stock[1])\n",
    "        stock.append(stock_return_values)\n",
    "\n",
    "        # Get the market return values\n",
    "        market_return_values = ut.market_return_values(stock[2])\n",
    "        stock.append(market_return_values)\n",
    "\n",
    "        # Convert newly created data back to dataframe\n",
    "        df_stock = pd.DataFrame(stock)\n",
    "\n",
    "        # Define window sizes \n",
    "        estimatation_window = ut.get_windows(df_stock, thres, event_size)\n",
    "        est_win_size = estimatation_window.shape[1]-1\n",
    "\n",
    "        # Get slope and intercept\n",
    "        stock_return_estw = estimatation_window.iloc[[3]].values[0][2:].tolist()\n",
    "        market_return_estw = estimatation_window.iloc[[4]].values[0][2:].tolist()\n",
    "        intercept, slope, stderr = ut.linear_regression(market_return_estw, stock_return_estw)\n",
    "\n",
    "        # Compute Standard deviation\n",
    "        lst1 = df_stock.iloc[3][thres:].to_list()\n",
    "        lst2 = df_stock.iloc[4][thres:].to_list()\n",
    "        std_dev = pd.DataFrame(list(zip(lst1, lst2))).std()[0]\n",
    "\n",
    "        # Compute Normal return\n",
    "        market_return = df_stock.iloc[4].values.tolist()[1:]\n",
    "        normal_return = ut.normal_return_values(market_return, slope, intercept)\n",
    "        stock.append(normal_return)\n",
    "\n",
    "        # Compute Abnormal return\n",
    "        abnormal_return = np.subtract(stock[3][1:],stock[5][1:]).tolist()\n",
    "        abnormal_return.insert(0,\"AbnormalReturn\")\n",
    "        stock.append(abnormal_return)\n",
    "\n",
    "        # Compute t-statistic R\n",
    "        abnormal_return = stock[6][1:]\n",
    "        t_stat_r = ut.t_stat_r(abnormal_return, stderr)\n",
    "        stock.append(t_stat_r)\n",
    "\n",
    "        # Put the stock data into a table again\n",
    "        df_stock = pd.DataFrame(stock)\n",
    "\n",
    "        # Get car value\n",
    "        abnormalReturn_event_window = df_stock.iloc[6][lower_idx:upper_idx]\n",
    "        car_value = abnormalReturn_event_window.sum()\n",
    "\n",
    "\n",
    "        # Get t-stat CAR\n",
    "        t_stat_car = car_value / (std_dev*(event_size)**(1/2))\n",
    "\n",
    "        # Collect all stocks together in one table \n",
    "        # --------------------------------------------\n",
    "        # Add stock meta-data to data table \n",
    "        row1 = [\"df_stockRow\", \"df_stock#\",\"intercept\", \"slope\", \"standard_error\", \"t_stat_car\", \"car_value\", \"eve_win_size\"]\n",
    "        row2 = [[(it*3), (it), intercept, slope, stderr, t_stat_car, car_value, event_size]]\n",
    "        variables = pd.DataFrame(row2)\n",
    "        variables.columns = row1\n",
    "\n",
    "        # Collect all stock data \n",
    "        stocks_data = pd.concat([stocks_data, df_stock], axis=0)\n",
    "        stocks_metadata = pd.concat([stocks_metadata, variables], axis=0)\n",
    "        \n",
    "\n",
    "    ### Pirate Calculations 1 ------------------------------------------ \n",
    "    df_AbnormalReturn = stocks_data.loc[stocks_data[0] == \"AbnormalReturn\"]\n",
    "\n",
    "    # Means for each column\n",
    "    aar_means = ut.mean(df_AbnormalReturn, lower_idx, upper_idx)\n",
    "\n",
    "    # Standard deviation for each column\n",
    "    aar_stds = ut.st_dev(df_AbnormalReturn, lower_idx, upper_idx)\n",
    "\n",
    "    # 1-sample T-test and P-value\n",
    "    aar_tstats, aar_pvalues = ut.t_test(df_AbnormalReturn, lower_idx, upper_idx)\n",
    "    \n",
    "    ### Pirate Calculations 2 ------------------------------------------ \n",
    "    \n",
    "    oddvalues = {}\n",
    "    # AAR Values \n",
    "    row1 = [\"AAR\", \"standardDev\", \"Tstat\", \"Pvalue\"]\n",
    "    row2 = [aar_means, aar_stds, aar_tstats, aar_pvalues]\n",
    "    variables = pd.DataFrame(row2)\n",
    "    variables = variables.T\n",
    "    variables.columns = row1\n",
    "\n",
    "    # CAAR Values\n",
    "    ev21 = variables[\"AAR\"].sum()\n",
    "    ev11 = variables[\"AAR\"][5:-5].sum()\n",
    "    ev5 = variables[\"AAR\"][7:-7].sum()\n",
    "    ev3 = variables[\"AAR\"][9:-9].sum()\n",
    "    CAAR = {\"ev21\": ev21, \"ev11\": ev11, \"ev5\": ev5, \"ev3\": ev3}\n",
    "    oddvalues[\"caar_value\"] = CAAR[\"ev21\"]\n",
    "\n",
    "    # CAAR standard deviations\n",
    "    caar_std = {}\n",
    "    carlist = []\n",
    "    for key, caar in CAAR.items():\n",
    "        for car in stocks_metadata[\"car_value\"]:\n",
    "            carlist.append((car-caar)**2)\n",
    "        caar_std[key] = math.sqrt(sum(carlist)/len(carlist))\n",
    "    oddvalues[\"caar_std\"] = caar_std[\"ev21\"]  \n",
    "\n",
    "    for i in zip(list(CAAR.values()), list(caar_std.values())):  \n",
    "        ttest = i[0]/i[1]\n",
    "        oddvalues[\"caar_tstat\"] = scipy.stats.t.sf(ttest, df=df_dnb.shape[0]/3-1)\n",
    "        break\n",
    "\n",
    "    # WilCoxon test\n",
    "    oddvalues[\"willCox_stat\"], oddvalues[\"willCox_pvalue\"] = scipy.stats.wilcoxon(stocks_metadata[\"car_value\"])\n",
    "    oddvalues = pd.DataFrame(oddvalues, index=[0])\n",
    "    \n",
    "    ### SAVE to EXCEL --------------------------------------------------  \n",
    "    print(\"Saving to excel...\")\n",
    "    # Create a Pandas Excel writer\n",
    "    path = \"export/\"+stock_csv+\"_winsize\"+str(event_size)+'.xlsx'\n",
    "    writer = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "\n",
    "    # Write each dataframe to a different worksheet.\n",
    "    stocks_data.to_excel(writer, sheet_name='data')\n",
    "    stocks_metadata.to_excel(writer, sheet_name='meta-data')\n",
    "    variables.to_excel(writer, sheet_name='AAR')\n",
    "    oddvalues.to_excel(writer, sheet_name='CAAR_n_Cox')\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "    print(\"Eventsize \"+str(event_size)+ \" completed!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
